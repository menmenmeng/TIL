{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 첫 번째 머신러닝 - 붓꽃 품종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "# 자체적으로 제공하는 데이터 세트를 생성하는 모듈 모임, 이 중에서 load_iris는 붓꽃 이미지 세트\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# sklearn.tree : 트리 기반 ML 알고리즘을 구현한 클래스의 모임\n",
    "from sklearn.model_selection import train_test_split\n",
    "# sklearn.model_selection : 학습/검증데이터 분리 or 평가 모듈 모임\n",
    "# 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈 모임.\n",
    "# 하이퍼 파라미터 : ML 알고리즘에서 최적의 학습을 위해 직접 입력하는 파라미터\n",
    "# ML 알고리즘의 성능 튜닝할 수 있다..\n",
    "# 최적의 하이퍼 파라미터로 평가하기 위한이 무슨 의미인지 아직은 모르겠음.\n",
    "\n",
    "# 붓꽃 데이터를 생성해서, DT를 이용해 분류하는 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target values :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target names :  ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris.data : 피처만으로 된 데이터 (쉽게 말하면 X변수들), np array로 되어 있다.\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris.target : 레이블(결정 값, y변수) 데이터, np array로 되어 있다.\n",
    "iris_label = iris.target\n",
    "print('iris target values : ', iris_label)\n",
    "print('iris target names : ', iris.target_names)\n",
    "\n",
    "# 붓꽃 데이터 DataFrame으로 변환\n",
    "iris_df = pd.DataFrame(iris_data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test data set 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2,\n",
    "                                                    random_state = 11)\n",
    "# train_test_split(x배열, y배열, test_size=num)과 같은 모양으로 하고\n",
    "# 반환은 x배열을 나눈 2개와 y배열을 나눈 2개가 들어있는 리스트로 만들어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 데이터와 레이블 데이터를 모두 numpy array로 넣었음. df 넣어도 되는지 확인해봄\n",
    "dfx_train, dfx_test, dfy_train, dfy_test = train_test_split(iris_df[iris.feature_names],\n",
    "                                                            iris_df['label'], \n",
    "                                                            test_size = 0.2, \n",
    "                                                            random_state = 11)\n",
    "# 해봤는데 되긴 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier객체 생성\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11) # random_state는 없어도 됨, 실습을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=11,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습수행\n",
    "dt_clf.fit(X_train, y_train) \n",
    "# 이러면 dt_clf의 파라미터가 트레인 데이터에 적응된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 완료된 dt_clf에서 predict()를 이용해서 테스트 데이터 결과 확인\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9333\n"
     ]
    }
   ],
   "source": [
    "# 예측 성능 평가 : 정확도 측정하기.\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "# label 데이터를 왼쪽에, predicted data를 오른쪽에 넣었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 세트 분리\n",
    "# 2. 모델 학습(.fit(X_train, y_train))\n",
    "# 3. 예측 수행(.pred(X_test))\n",
    "# 4. 평가(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런의 기반 프레임워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도학습 - Classification, Regression . 두 가지 지도학습 사이킷런 클래스를 Estimator\n",
    "# 라고 한다. 지도학습의 모든 알고리즘을 구현한 클래스 통칭함\n",
    "# Estimator 클래스는 fit(), predict() 메소드를 다 가지고 있다.\n",
    "\n",
    "# cross_val_score()와 같은 evaluation 함수나,\n",
    "# GridSearchCV와 같은 하이퍼 파리미터 튜닝을 지원하는 클래스\n",
    "# : 인자를 Estimator로 받음.\n",
    "# 인자로 받은 Estimator에 대해서 위의 평가함수나 그리드서치함수에서 fit, predict를 호출해서 평가\n",
    "# or 파라미터 튜닝을 수행함.\n",
    "\n",
    "# 비지도학습에서는 fit(), transform() 메소드를 적용. 이거는 비지도학습 때 다시 보기로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn 주요 모듈\n",
    "#### 예제 데이터\n",
    "- sklearn.datasets # 예시 파일들\n",
    "\n",
    "#### 피처 처리(전처리)\n",
    "- sklearn.preprocessing # 문자열 숫자형으로, 정규화, 스케일링 등 전처리 과정\n",
    "- sklearn.feature_selection # 변수 선택(더 중요한 변수 선택하는 기법).\n",
    "- sklearn.feature_extraction # 변수 추출.. 텍스트 데이터, 이미지 데이터 어쩌구 아직은 모름\n",
    "\n",
    "#### 피처 처리(차원 축소)\n",
    "- sklearn.decomposition # 차원 축소 관련 (PCA, NMF, Truncated SVD)\n",
    "\n",
    "#### 데이터 분리, 검증, 파라미터 튜닝\n",
    "- sklearn.model_selection # 학습용/테스트용 데이터 분리, 그리드 서치로 최적 하이퍼 파라미터 추출\n",
    "\n",
    "#### 평가\n",
    "- sklearn.metrics # 평가 기법(성능 측정 방법)\n",
    "\n",
    "#### ML 알고리즘들\n",
    "- sklearn.ensemble # 앙상블 알고리즘 (여러 개 묶어서 알고리즘 짜는거)\n",
    "- sklearn.linear_model # 선형 회귀, 릿지, 라쏘, 로지스틱 회귀 등.\n",
    "- sklearn.naive_bayes # 나이브 베이즈 알고리즘, 가우시안 NB, 다항 분포 NB\n",
    "- sklearn.neighbors # 최근접 이웃 알고리즘 (kNN 등)\n",
    "- sklearn.svm # 서포트 벡터 머신\n",
    "- sklearn.tree # 결정트리\n",
    "- sklearn.cluster # 비지도 클러스터링 알고리즘 (Kmeans, 계층형, DBSCAN..)\n",
    "\n",
    "#### 유틸리티 ( 뭐에 써먹는것? 모름)\n",
    "- sklearn.pipeline # 피처 처리 등. 변환과 ML알고리즘 학습, 예측 유틸리티 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장형 예제데이터 세트:\n",
    "# load_로 시작하는 것들 : 용량 작은거\n",
    "# fetch_로 시작하는 것들 : 용량 커서 인터넷에서 받아오는 거\n",
    "# make_로 시작하는 것들 : 표본 생성기, 분류나 클러스터링을 위한 데이터 세트를 무작위 생성(연습용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys= iris_data.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "['setosa' 'versicolor' 'virginica'] \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# x 변수들 이름 (features)\n",
    "print(type(iris_data.feature_names))\n",
    "print(len(iris_data.feature_names))\n",
    "print(iris_data.feature_names, '\\n')\n",
    "# y변수의 카테고리들 이름 (label category 이름들)\n",
    "print(type(iris_data.target_names))\n",
    "print(len(iris_data.target_names))\n",
    "print(iris_data.target_names, '\\n')\n",
    "# x 변수 데이터\n",
    "print(type(iris_data.data))\n",
    "print(iris_data.data.shape)\n",
    "print(iris_data.data, '\\n')\n",
    "# y 변수 데이터, label values.\n",
    "print(type(iris_data.target))\n",
    "print(iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# train set과 test set을 나누지 않고 fit\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습 데이터 세트로 예측\n",
    "pred = dt_clf.predict(train_data)\n",
    "print(\"정확도 :\", accuracy_score(train_label, pred))\n",
    "\n",
    "# 정확도가 1.0, 100%가 나옴.\n",
    "# dt_clf는 이미 train set에 최적으로 맞추어져 있으니\n",
    "# train set을 넣으면 무조건 정답을 맞출 수밖에 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                    test_size = 0.3, random_state = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터로 학습한 후, test 데이터로 정확도를 측정해 본다.\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(\"예측 정확도 : {0:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 교차검증\n",
    "과적합 : 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 할 경우 성능이 떨어지는 것.\n",
    "고정된 학습 데이터와 테스트 데이터로 평가를 하다 보면, 테스트 데이터에만 최적의 성능을 발휘하게 편향되는 경우가 생긴다.\n",
    "==> 해당 test data에만 과적합됨.\n",
    "\n",
    "=> 교차 검증을 이용해 다양하게 학습하고 평가한다\n",
    "\n",
    "- 교차검증을 통해 모든 데이터가 학습에도 사용되며, 동시에 검증에도 사용된다.\n",
    "- 대부분의 ML모델 성능 평가 : 교차 검증으로 1차 평가 후, 최종적으로 테스트 데이터 세트에 적용 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃데이터 세트 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "# K fold 교차 검증 : 데이터를 K개의 subset으로 나눈다.\n",
    "# 데이터 K개 세트가 각각 한 번씩 검증 데이터가 되어서 K번 학습/검증을 시행\n",
    "# K개의 평가를 평균한 결과를 가지고 예측 성능 평가.\n",
    "# KFold , StratifiedKFold(계층화?)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 5개 폴드 세트로 분리하는 KFold객체, 폴드 세트별 정확도 담는 리스트 객체 생성\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "print(\"붓꽃데이터 세트 크기 :\", features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
       "         47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,\n",
       "         77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "         103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "         116, 117, 118, 119])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119]),\n",
       "  array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "         146, 147, 148, 149]))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kfold.split은 어떤 모양의 데이터를 반환하는지?\n",
    "# (train_index1, test_index1), (train_index2, test_index2), ... , (train_index5, test_index5)\n",
    "# 튜플 묶음이 K번\n",
    "list(kfold.split(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 교차검증 정확도 : 1.0, 학습 데이터 크기 :           (120, 4), 검증 데이터 크기 : (30, 4)\n",
      "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "2번째 교차검증 정확도 : 0.9667, 학습 데이터 크기 :           (120, 4), 검증 데이터 크기 : (30, 4)\n",
      "#2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "3번째 교차검증 정확도 : 0.8333, 학습 데이터 크기 :           (120, 4), 검증 데이터 크기 : (30, 4)\n",
      "#3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "4번째 교차검증 정확도 : 0.9333, 학습 데이터 크기 :           (120, 4), 검증 데이터 크기 : (30, 4)\n",
      "#4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "5번째 교차검증 정확도 : 0.7333, 학습 데이터 크기 :           (120, 4), 검증 데이터 크기 : (30, 4)\n",
      "#5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " 평균 검증 정확도 :  0.9066599999999999\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()으로 반환된 인덱스를 이용해서 학습용, 검증용 데이터 추출하기.\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습, 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter+=1\n",
    "    # 반복할 때매다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4) # 소수점 4번째 자리까지 반올림표시\n",
    "    train_size = X_train.shape\n",
    "    test_size = X_test.shape\n",
    "    print(\"{0}번째 교차검증 정확도 : {1}, 학습 데이터 크기 : \\\n",
    "          {2}, 검증 데이터 크기 : {3}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    print(\"#{0} 검증 세트 인덱스 : {1}\".format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "\n",
    "# iteration accuracy 평균내기\n",
    "print(\"\\n 평균 검증 정확도 : \", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold \n",
    "데이터 label 집합에서 특정 레이블이 특이하게 많거나 적어서, 값 분포가 한쪽으로 치우칠 때 사용\n",
    "대출 사기(1), 정상 대출(0) 구별하는 모델 예시. 대출 사기는 매우 적고 정상 대출은 많아서, 0, 1 비율을 제대로 반영하지 못한다.\n",
    "\n",
    "StratifedKFold는 원본 데이터의 레이블 분포를 먼저 고려하고 나서, 이 분포와 동일한 분포로 학습/검증 데이터 분배한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "2    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "2    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "2    50\n",
      "Name: label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 붓꽃 데이터 그냥 KFold하기\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "x_iris = iris.data\n",
    "y_iris = iris.target\n",
    "iris_df = pd.DataFrame(x_iris, columns = iris.feature_names)\n",
    "iris_df['label'] = y_iris\n",
    "\n",
    "kfold = KFold(n_splits = 3)\n",
    "for train_index, test_index in kfold.split(iris_df): # split 안에는 x_iris, y_iris, iris_df..\\\n",
    "    # 여튼 index가 있는 것들이면 다 가능한 듯\n",
    "    label_train = iris_df['label'].iloc[train_index].value_counts()\n",
    "    label_test = iris_df['label'].iloc[test_index].value_counts()\n",
    "    print(train_values)\n",
    "    print(test_values, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 교차검증\n",
      "2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "2번째 교차검증\n",
      "2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "3번째 교차검증\n",
      "2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stratified kfold 사용\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, y_iris):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index].value_counts()\n",
    "    label_test = iris_df['label'].iloc[test_index].value_counts()\n",
    "    print(\"{}번째 교차검증\".format(n_iter))\n",
    "    print(label_train)\n",
    "    print(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 교차검증 정확도 :  0.9804\n",
      "2번째 교차검증 정확도 :  0.9216\n",
      "3번째 교차검증 정확도 :  0.9792\n",
      "교차검증 정확도 평균 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "# X데이터 따로, y데이터 따로의 np array를 미리 만들어 놓는 게 좋을 듯.\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "iris_df = pd.DataFrame(features, columns = iris.feature_names)\n",
    "iris_df['label'] = target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, test_idx in skfold.split(iris_df, iris_df['label']):\n",
    "    ## skfold(iris_df, iris_df.label)이 아니고.\n",
    "    ## skfold.split(iris_df, iris_df.label)입니다..헷갈리지 마세요\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = target[train_idx], target[test_idx]\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)  # 소수점 4번째 자리까지 표시\n",
    "    cv_accuracy.append(accuracy)\n",
    "    n_iter += 1\n",
    "    print(\"{}번째 교차검증 정확도 : \".format(n_iter), accuracy)\n",
    "\n",
    "print(\"교차검증 정확도 평균 : \", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류에서 거의 웬만하면 무조건 St.KFold 써라\n",
    "## 회귀에서는 St.KFold가 의미가 없으니 KFold 써라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위와 같은 교차 검증 간편하게 해주는 API : cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score() 선언 형태 :\n",
    "\n",
    "cross_val_score(estimator, X, y=None, scoring=None, cv=None, .....)\n",
    "\n",
    "위의 5개 항목이 주요 파라미터\n",
    "\n",
    "- estimator : 어떤 모델을 돌릴 것인지.\n",
    "- X : 피처 데이터 세트\n",
    "- y : 레이블 데이터\n",
    "- scoring : 예측 성능 평가 지표(위의 경우 accuracy_score였음)\n",
    "- cv : 교차 검증 폴드 수\n",
    "- 회귀에선 KFold, 분류에선 StratifiedKFold를 사용해서 교차검증해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증별 정확도 :  [0.9804 0.9216 0.9792]\n",
      "평균검증정확도 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "# cross_validate : 여러 개의 평가 지표 활용 가능. 어떻게 쓰는지 파라미터 확인해보기\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "iris_df = pd.DataFrame(iris_data.data, columns = iris_data.feature_names)\n",
    "iris_df['label'] = label\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv= 3)\n",
    "# scoring에 뭐가 들어갈 수 있는지 확인해보기.\n",
    "print('교차검증별 정확도 : ', np.round(scores, 4))\n",
    "print('평균검증정확도 : ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "하이퍼 파라미터 튜닝 방안. 아직 하이퍼 파라미터는 배우지 않았는데 그래도 선행학습 차원에서\n",
    "\n",
    "- 하이퍼 파라미터 : 머신러닝 알고리즘을 구성하는 주요 구성 요소.\n",
    "- 이 값을 조절해 알고리즘의 예측 성능을 개선할 수 있다.\n",
    "- Classifier, Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 최적의 파라미터 도출 방안을 제공한다.\n",
    "- Grid(격자), 촘촘하게 파라미터 입력하면서 테스트하는 방식.\n",
    "- 결정트리 알고리즘의 파라미터를 순차적으로 변경하면서 최고 성능의 파라미터 조합을 찾으려면.\n",
    "\n",
    "- 교차 검증 기반으로 하이퍼 파라미터의 최적값을 찾는다.\n",
    "- 데이터 세트를 cross-val 위한 학습/테스트 세트로 자동 분할한 뒤에, 모든 파라미터 순차 적용해 최적 파라미터. 수행시간이 상대적으로 오래 걸린다.\n",
    "- 5회에 걸쳐 하이퍼 파리미터 변경하면서, 수행 성능 측정. CV가 3회라면, 3개의 폴딩 세트를 3회에 걸쳐 학습.\n",
    "- CV 3, 하이퍼 파라미터 6개 조합이면 총 18번 학습/평가 이뤄진다.\n",
    "\n",
    "#### GridSarchCV 생성자\n",
    "\n",
    "- estimator : classifier, regressor, pipeline. 무슨 모델 사용할 것인지\n",
    "- param_grid : 파라미터명, 사용될 파라미터값\n",
    "- scoring : 평가 방법 지정, accuracy 문자열 또는 성능평가함수로 지정\n",
    "- cv : 교차 검증 분할 개수 지정\n",
    "- refit : True 생성시 가장 최적의 하이퍼 파라미터를 찾고 나서 estimator객체를 해당 하이퍼 파라미터로 재학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth':[1,2,3], 'min_samples_split': [2,3]}\n",
    "# max_depth : 트리 깊이가 어느정도 깊이일지.\n",
    "# min_samples_split은 아직 모르겠음\n",
    "\n",
    "# for문으로 파라미터를 하나하나 바꿔가면서 해야 하는 걸 API로 간편하게 사용 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로딩, 학습/테스트 분리.\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.2,\n",
    "                                                    random_state = 121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터 : 딕셔너리 형태로\n",
    "parameters = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 3개의 train, test set fold로 나누어 테스트 수행\n",
    "### refit = True가 디폴트, True면 가장 좋은 파라미터로 재 학습\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv = 3, refit = True)\n",
    "# GridSearchCV 객체 생성한 뒤,\n",
    "\n",
    "# 붓꽃 학습 데이터와 GridSearchCV.fit()메소드 이용해서 하이퍼파라미터 순차적 학습/평가.\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# 결과 추출해서 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_split': 2}\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "print(grid_dtree.best_params_)\n",
    "print(grid_dtree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "pred = estimator.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일반적으로 __학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행__하고 나서, __별도의 테스트 세트에서 이를 평가__한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "- Null 값 : Column 다 버리기에는 너무 중요한 데이터인데, 그렇기엔 Null값이 좀 많은 경우 대체값을 확실하게 잘 찾아야 함. 애매해서 어려움\n",
    "- 문자열 값 : Sklearn ML은 문자열을 입력값으로 허용하지 않는다. -> 인코딩을 통해 숫자형으로 변환되어야 함.\n",
    "- 문자열 피처 : 카테고리형 피처(코드값), 텍스트형 피처(피처 벡터화, 또는 불필요한 피처를 삭제)를 의미\n",
    "- 식별자 문자열 피처와 같은 경우는 인코딩하지 않고 삭제. 굳이 필요가 없음 예측에 중요하지 않으니까"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 인코딩\n",
    "- 레이블 인코딩, 원-핫 인코딩이 있다.\n",
    "- 레이블 인코딩 : 카테고리 피쳐를 코드형 숫자값으로 변환 (숫자형 값으로 변환되어야 함)\n",
    "- ex) TV 냉장고 전자레인지 -> 카테고리 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값 :  [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 레이블 인코딩 : LabelEncoder 클래스로 구현\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder 객체 생성 후, fit(), transform() 으로 레이블 인코딩\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값 : ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print('원본값:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주의 : 숫자형 값으로 변환되기 때문에 선형회귀 같은 데에서 컬럼을 숫자형 데이터로 인식해서 특정 카테고리에 가중치가 부여되는 등의 문제가 있을 수 있음, 그래서 이걸 해결하기 위한 인코딩으로 원-핫 인코딩을 함\n",
    "- 원-핫 인코딩 : 피처 값 유형에 따라 새로운 피쳐 추가해서, 고유 값에 해당하는 칼럼에만 1 표시하고 나머지 칼럼에는 0을 표시하는 방식.\n",
    "- 행 형태로 되어 있는 피처의 고유값을 열 형태로 변환한 뒤, 고유값에 해당하는 칼럼에만......\n",
    "- -> 카테고리 변수를 더미변수를 이용해서 변환하는 방식\n",
    "- 주의점 : OneHotEncoder 변환 전에 모든 문자열 값이 숫자형 값으로 변환되어야 함.(LabelEncoder 먼저 사용하고 그 뒤에 사용하는듯)\n",
    "- 주의점2 : 입력값으로 2차원 데이터가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫인코딩데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원핫인코딩데이터차원\n",
      "(8, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 숫자값으로 변환을 위해 LabelEncoder 변환\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# 2차원 데이터 변환\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# One-Hot Encoding 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('원핫인코딩데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원핫인코딩데이터차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas의 get_dummies()\n",
    "# 이게 더쉬워보임\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':items})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피처 스케일링, 정규화\n",
    "\n",
    "- 표준화(Standardization), 정규화(Normalization)\n",
    "- 표준화는 표준정규분포를 따르게 변환하는 것.\n",
    "- 정규화는 최소 0~ 최대 1의 값을 가지도록 min max 변화시켜주는 것.\n",
    "\n",
    "- 사이킷런에서 Normalizer 모듈은 선형대수 정규화 개념으로, 개별 벡터의 크기를 맞추기 위해 변환하는 것을 의미함.\n",
    "- 표준화 정규화는 한 개의 컬럼에 대해서, 사이킷런의 Normalizer는 동시에 여러 개의 컬럼에 대해서 진행하는 정규화라고 생각할수 있을듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 평균값\n",
      " sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "feature 분산값\n",
      " sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. StandardScaler (가우시안 분포 만들기)\n",
    "# SVM, 선형회귀, 로지스틱 회귀 는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현되었다.\n",
    "# 사전에 표준화 적용하는 것이 중요한 요소가 됨.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris.data, columns = iris.feature_names)\n",
    "\n",
    "print('feature 평균값\\n', iris_df.mean())\n",
    "print('feature 분산값\\n', iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 평균값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "feature 분산값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(iris_scaled, columns = iris.feature_names)\n",
    "print('feature 평균값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('feature 분산값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "feature 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. MinMaxScaler\n",
    "# 0~1사이의 값으로 변환(음수값이 있으면 -1~1사이로 변환)\n",
    "# 데이터 분포가 가우시안이 아닐 경우 Min, Max Scale 적용.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(iris_scaled, columns = iris.feature_names)\n",
    "print('feature 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('feature 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터, 테스트 데이터의 스케일링 변환시 유의점\n",
    "\n",
    "- fit(), transform(), fit_transform() 을 이용.\n",
    "- fit() : 객체에 데이터 변환 기준 정보 설정.\n",
    "- transform() : 설정된 정보를 이용해 데이터를 변환\n",
    "- fit_transform() : 한번에 해줌\n",
    "\n",
    "- 그러니까 처음에 학습 데이터 할때는 fit_transform() 해도 되는데, 테스트 데이터를 학습 데이터와 같은 식으로 데이터 변환하려면 fit_transform()이 아니라 transform()만 해야된다!!! fit_transform()하면 테스트 데이터에 맞춘 새로운 스케일링 정보가 저장되어서 그걸로 스케일링되기 때문에 모델이 달라진다.\n",
    "\n",
    "\n",
    "##### 주의사항 정리\n",
    "- __전체 데이터를 스케일링 변환한 뒤 학습-테스트 데이터로 분리할 것__\n",
    "- __그게 안 되면 적어도 fit_transform()을 테스트 데이터에 사용하지 말 것.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런 - 타이타닉 생존자 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('titanic/titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 정보\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null값 : Age, Cabin, Embarked에 있다.\n",
    "# Age는 평균 나이로, Cabin과 Embarked는 N이라는 문자로 변경한다.\n",
    "titanic_df.Age.fillna(titanic_df.Age.mean(), inplace= True)\n",
    "titanic_df.Cabin.fillna('N', inplace = True)\n",
    "titanic_df.Embarked.fillna('N', inplace = True)\n",
    "titanic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "N              687\n",
      "C23 C25 C27      4\n",
      "B96 B98          4\n",
      "G6               4\n",
      "E101             3\n",
      "F2               3\n",
      "D                3\n",
      "C22 C26          3\n",
      "F33              3\n",
      "E67              2\n",
      "B20              2\n",
      "C123             2\n",
      "E121             2\n",
      "D20              2\n",
      "D26              2\n",
      "D33              2\n",
      "C65              2\n",
      "D17              2\n",
      "F G73            2\n",
      "C78              2\n",
      "B51 B53 B55      2\n",
      "B49              2\n",
      "C2               2\n",
      "E24              2\n",
      "C83              2\n",
      "D36              2\n",
      "C52              2\n",
      "C124             2\n",
      "E8               2\n",
      "E25              2\n",
      "              ... \n",
      "D15              1\n",
      "B80              1\n",
      "B102             1\n",
      "D21              1\n",
      "F G63            1\n",
      "B50              1\n",
      "D46              1\n",
      "C90              1\n",
      "B4               1\n",
      "C95              1\n",
      "E58              1\n",
      "C99              1\n",
      "B3               1\n",
      "B42              1\n",
      "C49              1\n",
      "C128             1\n",
      "D11              1\n",
      "E63              1\n",
      "B82 B84          1\n",
      "D49              1\n",
      "E34              1\n",
      "C118             1\n",
      "D9               1\n",
      "C46              1\n",
      "C91              1\n",
      "D6               1\n",
      "C85              1\n",
      "C110             1\n",
      "E10              1\n",
      "A26              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 문자열 피쳐 : Sex, Cabin, Embarked. 값 분류 얼마나 되는지 보자.\n",
    "\n",
    "print(titanic_df.Sex.value_counts())\n",
    "print(titanic_df.Cabin.value_counts())\n",
    "print(titanic_df.Embarked.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sex와 Embarked는 카테고리로 되어 있음\n",
    "# Cabin은 C23 C25 C27 이라는 값이나, F    0125 뭐이런것처럼 정리가 안되어 있다.\n",
    "# Cabin은 선실 번호 중에서 선실 등급을 나타내는 첫 번째 알파벳이 중요할 것. ** 이런거\n",
    "\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df.Cabin.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성별에 따른 생존자 수 비교\n",
    "\n",
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1deef62a630>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1deef713240>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data = titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1 : cat = 'Unknown'\n",
    "    elif age <= 5 : cat = 'Baby'\n",
    "    elif age <= 12 : cat = 'Child'\n",
    "    elif age <= 18 : cat = 'Teenager'\n",
    "    elif age <= 25 : cat = 'Student'\n",
    "    elif age <= 35 : cat = 'Young Adult'\n",
    "    elif age <= 60 : cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "        \n",
    "    return cat\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', \n",
    "               'Elderly']\n",
    "\n",
    "\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x: get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order = group_names)\n",
    "titanic_df.drop('Age_cat', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열 카테고리를 숫자형으로 변환하기 : LabelEncoder 이용.\n",
    "# 여러 칼럼을 encode_features()함수를 생성해서 한 번에 변환한다.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터, 이 과정을 한번에 하는 함수 만들어서 df를 이 함수에 적용시켰음\n",
    "\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace = True)\n",
    "    df['Cabin'].fillna('N', inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    df['Fare'].fillna(0, inplace = True)\n",
    "    return df\n",
    "    \n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('titanic/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop(['Survived'], axis = 1, inplace = False)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\n",
    "                                                    test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877\n",
      "0.8324\n",
      "0.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 각 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# DT 학습/예측 평가\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(np.round(accuracy, 4))\n",
    "\n",
    "# RF 학습\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(np.round(accuracy, 4))\n",
    "\n",
    "# LR 학습\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(np.round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 0번째 정확도 : 0.7542\n",
      "교차검증 1번째 정확도 : 0.7809\n",
      "교차검증 2번째 정확도 : 0.7865\n",
      "교차검증 3번째 정확도 : 0.7697\n",
      "교차검증 4번째 정확도 : 0.8202\n",
      "평균정확도 : 0.7823\n",
      "교차검증 0번째 정확도 : 0.7989\n",
      "교차검증 1번째 정확도 : 0.7640\n",
      "교차검증 2번째 정확도 : 0.8202\n",
      "교차검증 3번째 정확도 : 0.7921\n",
      "교차검증 4번째 정확도 : 0.8315\n",
      "평균정확도 : 0.8013\n",
      "교차검증 0번째 정확도 : 0.7933\n",
      "교차검증 1번째 정확도 : 0.7921\n",
      "교차검증 2번째 정확도 : 0.7753\n",
      "교차검증 3번째 정확도 : 0.7472\n",
      "교차검증 4번째 정확도 : 0.8427\n",
      "평균정확도 : 0.7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# KFold를 사용해서 예측해보기\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds = 5):\n",
    "    kfold = KFold(n_splits = folds)\n",
    "    scores = []\n",
    "    \n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        \n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차검증 {}번째 정확도 : {:.4f}\".format(iter_count, accuracy))\n",
    "        \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균정확도 : {:.4}\".format(mean_score))\n",
    "\n",
    "exec_kfold(dt_clf, folds=5)\n",
    "exec_kfold(rf_clf, folds=5)\n",
    "exec_kfold(lr_clf, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 0번째 정확도 : 0.7430\n",
      "교차검증 1번째 정확도 : 0.7765\n",
      "교차검증 2번째 정확도 : 0.7809\n",
      "교차검증 3번째 정확도 : 0.7753\n",
      "교차검증 4번째 정확도 : 0.8418\n",
      "평균정확도: 0.7835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print(\"교차검증 {}번째 정확도 : {:.4f}\".format(iter_count, accuracy))\n",
    "    \n",
    "print(\"평균정확도: {:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적하이퍼파라미터 :  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "최고정확도 : 0.7992\n",
      "테스트세트 DTC정확도 : 0.8715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV 사용\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth' : [2, 3, 5, 10], \n",
    "              'min_samples_split' : [2, 3, 5],\n",
    "              'min_samples_leaf' : [1, 5, 8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid = parameters, scoring = 'accuracy', cv = 5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print(\"최적하이퍼파라미터 : \", grid_dclf.best_params_)\n",
    "print(\"최고정확도 : {:.4f}\".format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print(\"테스트세트 DTC정확도 : {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
