{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.82\n",
      "RandomForestClassifier 0.8366666666666667\n",
      "SVC 0.8566666666666667\n",
      "VotingClassifier 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(clf.__class__.__name__, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533333333333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting\n",
    "투표를 통해 예측값을 결정함,  \n",
    "hard voting/soft voting있음. hard voting은 개수를 따지는 것, soft voting은 확률합을 따지는 것.\n",
    "\n",
    "#### Bagging, Pasting\n",
    "bagging : bootstrap sampling, 하나의 sample 안에 중복된 데이터가 존재할 수 있음  \n",
    "pasting : 하나의 sample안에는 무조건 unique한 데이터만 있어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oob 평가\n",
    "out of bag words. 하나의 예측기마다 학습을 위해 샘플링되는 데이터의 비율은 전체 대비 63% 정도. m이 커지면 커질수록, 그 값이 63%에 가까워진다. 남은 37%를 가지고, 앙상블을 구성하는 하나하나의 예측기를 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371428571428572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30813953, 0.69186047],\n",
       "       [0.0060241 , 0.9939759 ],\n",
       "       [0.06043956, 0.93956044],\n",
       "       ...,\n",
       "       [0.73033708, 0.26966292],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.47368421, 0.52631579]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 중요도 (feature importances)\n",
    "RF의 모든 트리에 걸쳐서, 특성의 분할이 일어났을 때 어떤 특성이 더 불순도를 많이 감소시키냐? 를 측정해서 feature importance를 계산  \n",
    "불순도는 연관된 샘플의 수에 따라 가중평균됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainVal, X_test, y_trainVal, y_test = train_test_split(X, y, test_size=1/7)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, test_size=1/6)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_accuracy  : 0.9683\n",
      "et_accuracy  : 0.9689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_accuracy  : 0.9194\n",
      "svc_accuracy : 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard_accuracy: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(vt_clf_hard\u001b[38;5;241m.\u001b[39mpredict(X_val), y_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m vt_clf_soft\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(\u001b[43mvt_clf_soft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m, y_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:364\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    362\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoting \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msoft\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     maj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    366\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# 'hard' voting\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict(X)\n",
      "File \u001b[1;32mc:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:405\u001b[0m, in \u001b[0;36mVotingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    404\u001b[0m avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(\n\u001b[1;32m--> 405\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect_probas(X), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_not_none\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m avg\n",
      "File \u001b[1;32mc:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:380\u001b[0m, in \u001b[0;36mVotingClassifier._collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_collect_probas\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    379\u001b[0m     \u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([clf\u001b[39m.\u001b[39mpredict_proba(X) \u001b[39mfor\u001b[39;00m clf \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\n",
      "File \u001b[1;32mc:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_collect_probas\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    379\u001b[0m     \u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([clf\u001b[39m.\u001b[39;49mpredict_proba(X) \u001b[39mfor\u001b[39;00m clf \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\n",
      "File \u001b[1;32mc:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     26\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[0;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m     34\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32mc:\\TIL\\ML\\venv_ml\\lib\\site-packages\\sklearn\\svm\\_base.py:829\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_proba\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobability:\n\u001b[1;32m--> 829\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    830\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpredict_proba is not available when  probability=False\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m         )\n\u001b[0;32m    832\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mc_svc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnu_svc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    833\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC # ?? 이게 맞을까? SVM을 잘 공부하지 못했으니까 고민해보기.....\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 1. Random Forest Classifier\n",
    "# 2. Extra Tree Classifier\n",
    "# 3. Logistic Regression\n",
    "# 4. SVM\n",
    "\n",
    "# 1. Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=100)\n",
    "lr_clf = LogisticRegression()\n",
    "svc = SVC()\n",
    "vt_clf_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier()), \n",
    "        ('et', ExtraTreesClassifier()), \n",
    "        ('lr', LogisticRegression()),\n",
    "        ('svc', SVC())\n",
    "    ], \n",
    "    voting='hard'\n",
    ")\n",
    "vt_clf_soft = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier()), \n",
    "        ('et', ExtraTreesClassifier()), \n",
    "        ('lr', LogisticRegression()),\n",
    "        ('svc', SVC())\n",
    "    ], \n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "print(f'rf_accuracy  : {accuracy_score(rf_clf.predict(X_val), y_val)}')\n",
    "et_clf.fit(X_train, y_train)\n",
    "print(f'et_accuracy  : {accuracy_score(et_clf.predict(X_val), y_val)}')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "print(f'lr_accuracy  : {accuracy_score(lr_clf.predict(X_val), y_val)}')\n",
    "svc.fit(X_train, y_train)\n",
    "print(f'svc_accuracy : {accuracy_score(svc.predict(X_val), y_val)}')\n",
    "vt_clf_hard.fit(X_train, y_train)\n",
    "print(f'hard_accuracy: {accuracy_score(vt_clf_hard.predict(X_val), y_val)}')\n",
    "vt_clf_soft.fit(X_train, y_train)\n",
    "print(f'soft_accuracy: {accuracy_score(vt_clf_soft.predict(X_val), y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv_ml': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34f79edca71b491da1184107855aae9e808535a0ee8a0ea99ef7c0ae573f9e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
