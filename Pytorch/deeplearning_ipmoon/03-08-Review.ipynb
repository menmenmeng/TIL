{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리들 (사용 가능한 라이브러리)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LR\n",
    "# 모델식과 W, b를 직접 정의하고, requires_grad=True로 놓았다.\n",
    "# ** 기본적인 pytorch의 코드 작성 방법\n",
    "# 1. x_train, y_train이 있음\n",
    "# 2. x_train을 선형 조합 OR 기타 등등 식으로 계산하여 prediction을 만드는 식에서,\n",
    "# ~2. 그 식의 파라미터를 설정(LR의 경우, W와 b를 정의하면 됨)\n",
    "# 3. optimizer를 설정\n",
    "# 4. prediction을 이용해 cost function 정의하고,\n",
    "# ~4. step을 밟아가며, optimizer.zero_grad(), cost.backward(), optimizer.step() 을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비 : (3, 1). 데이터 하나는 (1,)의 사이즈를 가짐. \n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. W, b 설정\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost 18.6667, W, b 0.18666668236255646, 0.07999999821186066\n",
      "Epoch 200, Cost 0.0298, W, b 1.80009925365448, 0.4544214904308319\n",
      "Epoch 400, Cost 0.0114, W, b 1.876473307609558, 0.28080499172210693\n",
      "Epoch 600, Cost 0.0043, W, b 1.9236682653427124, 0.1735200434923172\n",
      "Epoch 800, Cost 0.0017, W, b 1.952831506729126, 0.10722480714321136\n",
      "Epoch 1000, Cost 0.0006, W, b 1.9708527326583862, 0.06625857204198837\n",
      "Epoch 1200, Cost 0.0002, W, b 1.9819889068603516, 0.04094360023736954\n",
      "Epoch 1400, Cost 0.0001, W, b 1.9888702630996704, 0.025300635024905205\n",
      "Epoch 1600, Cost 0.0000, W, b 1.9931223392486572, 0.015634294599294662\n",
      "Epoch 1800, Cost 0.0000, W, b 1.995750069618225, 0.009661080315709114\n",
      "Epoch 2000, Cost 0.0000, W, b 1.9973737001419067, 0.005970162805169821\n"
     ]
    }
   ],
   "source": [
    "# 4. 반복문에서 prediction 및 cost를 계산하고, optimizer를 업데이트\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = x_train * W + b\n",
    "    cost = torch.mean((prediction-y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%200 == 0:\n",
    "        print(f\"Epoch {epoch}, Cost {cost:.4f}, W, b {W.item()}, {b.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9974, 3.9947, 5.9921], grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주의 !!!!!!!!!!!! \n",
    "# x_train.shape : (3, 1)\n",
    "# W.shape : (1,)\n",
    "# x_train.matmul(W) 하면, 왜 (3,) 모양이 되어서 나오는 걸까\n",
    "x_train @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9974],\n",
       "        [3.9947],\n",
       "        [5.9921]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간 과정의 shape를 항상 잘 관찰해야 할 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Cost : 29661.80078125, W : tensor([0.2940, 0.2936, 0.2902]), b : 0.0034\n",
      "Epoch : 20, Cost : 5.957088947296143, W : tensor([0.6807, 0.6785, 0.6677]), b : 0.0079\n",
      "Epoch : 40, Cost : 5.90573787689209, W : tensor([0.6826, 0.6791, 0.6652]), b : 0.0079\n",
      "Epoch : 60, Cost : 5.854844093322754, W : tensor([0.6844, 0.6797, 0.6627]), b : 0.0080\n",
      "Epoch : 80, Cost : 5.804478168487549, W : tensor([0.6863, 0.6803, 0.6602]), b : 0.0080\n",
      "Epoch : 100, Cost : 5.754572868347168, W : tensor([0.6882, 0.6809, 0.6577]), b : 0.0080\n"
     ]
    }
   ],
   "source": [
    "# 2. MLR\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs+1):\n",
    "    prediction = x_train @ W + b\n",
    "    cost = torch.mean((prediction-y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%20==0:\n",
    "        print(f\"Epoch : {epoch}, Cost : {cost}, W : {W.squeeze().detach()}, b : {b.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Cost : 23126.0508\n",
      "Epoch 200 | Cost : 2.1575\n",
      "Epoch 400 | Cost : 1.9753\n",
      "Epoch 600 | Cost : 1.8114\n",
      "Epoch 800 | Cost : 1.6639\n",
      "Epoch 1000 | Cost : 1.5309\n",
      "Epoch 1200 | Cost : 1.4109\n",
      "Epoch 1400 | Cost : 1.3023\n",
      "Epoch 1600 | Cost : 1.2041\n",
      "Epoch 1800 | Cost : 1.1150\n",
      "Epoch 2000 | Cost : 1.0342\n"
     ]
    }
   ],
   "source": [
    "# 3. nn.Module을 활용해서.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 준비\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "# 모델 작성\n",
    "class MultilinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# 학습\n",
    "model = MultilinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%200==0:\n",
    "        print(f\"Epoch {epoch} | Cost : {cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.0028, 0.6679, 0.3475]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4180], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. minibatch & CustomDataset\n",
    "# Dataset과 DataLoader를 사용해서 학습해 보기.\n",
    "# TensorDataset을 이용해서 dataset 인스턴스에 바로 담을 수도 있고, 따로 CustomDataset 클래스를 작성해도 된다.\n",
    "# DataLoader사용법 : Dataset, 그리고 batch size, 그리고 shuffle 인자 (T/F). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Cost:31283.7168\n",
      "Epoch:0, Cost:14801.9883\n",
      "Epoch:0, Cost:4748.5518\n",
      "Epoch:100, Cost:3.1086\n",
      "Epoch:100, Cost:0.8268\n",
      "Epoch:100, Cost:1.4172\n",
      "Epoch:200, Cost:0.1347\n",
      "Epoch:200, Cost:3.4244\n",
      "Epoch:200, Cost:0.0498\n",
      "Epoch:300, Cost:0.7679\n",
      "Epoch:300, Cost:2.2122\n",
      "Epoch:300, Cost:1.1518\n",
      "Epoch:400, Cost:0.1054\n",
      "Epoch:400, Cost:2.4241\n",
      "Epoch:400, Cost:0.8306\n",
      "Epoch:500, Cost:1.9649\n",
      "Epoch:500, Cost:0.3883\n",
      "Epoch:500, Cost:0.0244\n",
      "Epoch:600, Cost:0.2439\n",
      "Epoch:600, Cost:0.1579\n",
      "Epoch:600, Cost:3.4027\n",
      "Epoch:700, Cost:0.1865\n",
      "Epoch:700, Cost:1.4582\n",
      "Epoch:700, Cost:0.8745\n",
      "Epoch:800, Cost:0.2825\n",
      "Epoch:800, Cost:1.1191\n",
      "Epoch:800, Cost:0.1020\n",
      "Epoch:900, Cost:0.4407\n",
      "Epoch:900, Cost:0.9676\n",
      "Epoch:900, Cost:0.1438\n",
      "Epoch:1000, Cost:0.1754\n",
      "Epoch:1000, Cost:0.2457\n",
      "Epoch:1000, Cost:1.6926\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# 데이터 준비\n",
    "x_train = torch.FloatTensor([[73,  80,  75], \n",
    "                             [93,  88,  93], \n",
    "                             [89,  91,  80], \n",
    "                             [96,  98,  100],   \n",
    "                             [73,  66,  70]])  \n",
    "y_train = torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "# 모델 작성\n",
    "class MultilinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Dataset 작성\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 학습하기\n",
    "model = MultilinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x, y = samples\n",
    "        \n",
    "        prediction = model(x)\n",
    "        cost = F.mse_loss(prediction, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch%100==0:\n",
    "            print(f\"Epoch:{epoch}, Cost:{cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.1038, 0.6552, 0.2675]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0334], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Cost : 34753.7109\n",
      "Epoch : 0, Cost : 17489.5020\n",
      "Epoch : 0, Cost : 2682.8364\n",
      "Epoch : 200, Cost : 17.5161\n",
      "Epoch : 200, Cost : 2.9873\n",
      "Epoch : 200, Cost : 1.1517\n",
      "Epoch : 400, Cost : 1.8183\n",
      "Epoch : 400, Cost : 12.0921\n",
      "Epoch : 400, Cost : 1.9551\n",
      "Epoch : 600, Cost : 0.3746\n",
      "Epoch : 600, Cost : 0.0328\n",
      "Epoch : 600, Cost : 17.4188\n",
      "Epoch : 800, Cost : 0.0275\n",
      "Epoch : 800, Cost : 5.9883\n",
      "Epoch : 800, Cost : 0.3663\n",
      "Epoch : 1000, Cost : 0.1827\n",
      "Epoch : 1000, Cost : 3.6919\n",
      "Epoch : 1000, Cost : 1.6275\n",
      "Epoch : 1200, Cost : 0.1884\n",
      "Epoch : 1200, Cost : 2.8825\n",
      "Epoch : 1200, Cost : 0.7437\n",
      "Epoch : 1400, Cost : 1.2062\n",
      "Epoch : 1400, Cost : 0.9640\n",
      "Epoch : 1400, Cost : 0.5070\n",
      "Epoch : 1600, Cost : 0.2554\n",
      "Epoch : 1600, Cost : 0.1195\n",
      "Epoch : 1600, Cost : 2.8323\n",
      "Epoch : 1800, Cost : 0.9704\n",
      "Epoch : 1800, Cost : 0.1166\n",
      "Epoch : 1800, Cost : 0.2465\n",
      "Epoch : 2000, Cost : 0.1550\n",
      "Epoch : 2000, Cost : 0.1988\n",
      "Epoch : 2000, Cost : 1.4903\n"
     ]
    }
   ],
   "source": [
    "# 이번엔 CustomDataset 사용\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 모델 작성\n",
    "class MultilinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Dataset 작성\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data  =  torch.FloatTensor([[73,  80,  75], \n",
    "                                    [93,  88,  93], \n",
    "                                    [89,  91,  80], \n",
    "                                    [96,  98,  100],   \n",
    "                                    [73,  66,  70]])  \n",
    "        self.y_data  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x, y\n",
    "\n",
    "# 학습하기\n",
    "model = MultilinearRegressionModel()\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x, y = samples\n",
    "        prediction = model(x)\n",
    "        cost = F.mse_loss(prediction, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if epoch%200==0:\n",
    "            print(f\"Epoch : {epoch}, Cost : {cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.1177, 0.6510, 0.2519]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4651], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Model의 define해야 하는 메소드\n",
    "# 1. __init__(super init 필수), 2. forward(self, x)\n",
    "# Custom Dataset의 필수 메소드\n",
    "# 1. __init__(super init 필요 없음), 2. __len__, 3. __getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f8b5fff75b2d8ca621f0b371f1d64751a06b7789195e8887ef7855e4487b82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
