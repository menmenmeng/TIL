{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방대한 양의 데이터는 한 번에 전부를 학습하면서 경사 하강법을 수행하면 수행 속도가 매우 느리게 진행될 것.\n",
    "# 많은 계산량이 필요하므로 메모리도 많이 잡아먹는다.\n",
    "# --> 전체 데이터를 더 작은 단위로 나눠서 그 단위로 학습하는 미니 배치 경사 하강법 개념이 나오게 되었다.\n",
    "# (업데이트 한 번에 전체 데이터를 사용하는 것을 배치 경사 하강법, 미니 배치를 사용하면 미니 배치 경사 하강법)\n",
    "\n",
    "# Epoch, Mini batch, Iteration에 대해\n",
    "# Epoch : 전체 데이터를 몇 번 사용할 것인가\n",
    "# Mini batch : 전체 데이터를 몇 개의 미니 배치로 쪼갤 것인가\n",
    "# Iteration : 그래서 몇 번 업데이트 하는가(Epoch * Minibatch)\n",
    "# ** 배치 크기(미니 배치 하나의 사이즈)는 일반적으로 2의 제곱수. why? CPU, GPU의 메모리가 2의 배수이기 때문에\n",
    "# 2의 배수로 할 경우 데이터 송수신 효율을 높일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 쉽게 다루는 도구로서, 데이터셋(Dataset)과 데이터로더(DataLoader)를 제공한다.\n",
    "# 미니 배치 학습, 데이터 셔플, 병렬 처리를 지원하는 기능\n",
    "# 기본적 사용 방법 :\n",
    "## Dataset 정의 --> DataLoader에 전달.\n",
    "# 여기서는 텐서를 입력받아서 Dataset의 형태로 변환해주는 TensorDataset을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TensorDataset, DataLoader 임포트\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train Tensor를 TensorDataset에 인자로 전달하여, dataset으로 저장\n",
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset을 만들었다면, DataLoader를 사용 가능하다. 데이터로더는 2개의 인자를 입력받는다.\n",
    "# 1. 데이터셋\n",
    "# 2. 미니 배치 size(통상적으로 2의 제곱수)\n",
    "# 3. (optional): shuffle = True를 선택하면 Epoch마다 데이터셋을 섞어서, 데이터 학습 순서를 바꾼다. 좋아보임\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
      "        [152.]])]\n",
      "0, 0, 8970.6875\n",
      "1\n",
      "[tensor([[93., 88., 93.],\n",
      "        [89., 91., 90.]]), tensor([[185.],\n",
      "        [180.]])]\n",
      "0, 1, 2943.9248046875\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "0, 2, 530.4251098632812\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "1, 0, 224.3378143310547\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
      "        [180.]])]\n",
      "1, 1, 145.4307403564453\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "1, 2, 71.75151824951172\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [93., 88., 93.]]), tensor([[152.],\n",
      "        [185.]])]\n",
      "2, 0, 8.944786071777344\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "2, 1, 4.62497091293335\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "2, 2, 0.025081364437937737\n",
      "0\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "3, 0, 3.3967230319976807\n",
      "1\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 66., 70.]]), tensor([[180.],\n",
      "        [142.]])]\n",
      "3, 1, 3.327021598815918\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "3, 2, 4.122939586639404\n",
      "0\n",
      "[tensor([[89., 91., 90.],\n",
      "        [93., 88., 93.]]), tensor([[180.],\n",
      "        [185.]])]\n",
      "4, 0, 4.088062286376953\n",
      "1\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "4, 1, 4.195919513702393\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "4, 2, 0.15231382846832275\n",
      "0\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 80., 75.]]), tensor([[180.],\n",
      "        [152.]])]\n",
      "5, 0, 1.946873426437378\n",
      "1\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 66., 70.]]), tensor([[185.],\n",
      "        [142.]])]\n",
      "5, 1, 8.623043060302734\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "5, 2, 0.8132056593894958\n",
      "0\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "6, 0, 2.452901840209961\n",
      "1\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 66., 70.]]), tensor([[180.],\n",
      "        [142.]])]\n",
      "6, 1, 3.332313060760498\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "6, 2, 4.50441312789917\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [93., 88., 93.]]), tensor([[152.],\n",
      "        [185.]])]\n",
      "7, 0, 4.5590105056762695\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "7, 1, 3.4319441318511963\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "7, 2, 0.17682169377803802\n",
      "0\n",
      "[tensor([[ 73.,  66.,  70.],\n",
      "        [ 96.,  98., 100.]]), tensor([[142.],\n",
      "        [196.]])]\n",
      "8, 0, 2.8781871795654297\n",
      "1\n",
      "[tensor([[89., 91., 90.],\n",
      "        [93., 88., 93.]]), tensor([[180.],\n",
      "        [185.]])]\n",
      "8, 1, 3.061267852783203\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "8, 2, 4.333710670471191\n",
      "0\n",
      "[tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "9, 0, 0.3160865604877472\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]]), tensor([[142.],\n",
      "        [152.]])]\n",
      "9, 1, 4.573093891143799\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "9, 2, 6.65129280090332\n",
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 80., 75.]]), tensor([[185.],\n",
      "        [152.]])]\n",
      "10, 0, 4.047603607177734\n",
      "1\n",
      "[tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "10, 1, 2.551802158355713\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "10, 2, 5.384699821472168\n",
      "0\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 66., 70.]]), tensor([[180.],\n",
      "        [142.]])]\n",
      "11, 0, 3.4862210750579834\n",
      "1\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "11, 1, 1.7677273750305176\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "11, 2, 5.706045150756836\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [89., 91., 90.]]), tensor([[152.],\n",
      "        [180.]])]\n",
      "12, 0, 1.7321962118148804\n",
      "1\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "12, 1, 4.731764316558838\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "12, 2, 4.8559112548828125\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "13, 0, 4.418611526489258\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
      "        [180.]])]\n",
      "13, 1, 2.4737114906311035\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "13, 2, 5.20528507232666\n",
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 80., 75.]]), tensor([[185.],\n",
      "        [152.]])]\n",
      "14, 0, 4.150850296020508\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
      "        [180.]])]\n",
      "14, 1, 2.8087222576141357\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "14, 2, 5.207374095916748\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [89., 91., 90.]]), tensor([[152.],\n",
      "        [180.]])]\n",
      "15, 0, 5.2081098556518555\n",
      "1\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "15, 1, 2.8547182083129883\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "15, 2, 3.8928778171539307\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [93., 88., 93.]]), tensor([[142.],\n",
      "        [185.]])]\n",
      "16, 0, 1.5515494346618652\n",
      "1\n",
      "[tensor([[73., 80., 75.],\n",
      "        [89., 91., 90.]]), tensor([[152.],\n",
      "        [180.]])]\n",
      "16, 1, 9.118428230285645\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "16, 2, 0.4324081838130951\n",
      "0\n",
      "[tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "17, 0, 0.7576338052749634\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [93., 88., 93.]]), tensor([[142.],\n",
      "        [185.]])]\n",
      "17, 1, 6.787056922912598\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "17, 2, 5.541909217834473\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "18, 0, 3.503960132598877\n",
      "1\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "18, 1, 2.5402896404266357\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "18, 2, 4.485649585723877\n",
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 80., 75.]]), tensor([[185.],\n",
      "        [152.]])]\n",
      "19, 0, 4.43132209777832\n",
      "1\n",
      "[tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "19, 1, 0.7391993999481201\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "19, 2, 6.661370754241943\n",
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
      "        [185.]])]\n",
      "20, 0, 1.7815377712249756\n",
      "1\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "20, 1, 4.192310810089111\n",
      "2\n",
      "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
      "20, 2, 3.2283759117126465\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1): # 각 에포크마다.\n",
    "    for batch_idx, samples in enumerate(dataloader): # 데이터로더에서 지원하는 각 미니배치 개수만큼 for문\n",
    "        print(batch_idx)\n",
    "        print(samples)\n",
    "        x_train, y_train = samples\n",
    "\n",
    "        prediction = model(x_train)\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"{epoch}, {batch_idx}, {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개 있기 때문에, 마지막 mini batch는 한 개의 데이터를 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.4668]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f8b5fff75b2d8ca621f0b371f1d64751a06b7789195e8887ef7855e4487b82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
